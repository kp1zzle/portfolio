---
title: "Neural Networks for Artists"
date: "Spring 2019"
slug: "neural-networks-for-artists"
hero_image: "./hero.jpg"
hero_image_alt: "neural net diagram"
short_description: "How can artists use neural networks as creative tools?"
long_description: "How can artists use neural networks as creative tools? I analyzed the uses of this technology and how artists could change configuration and hyper-parameters to achieve desired results. Finally, I suggested a graphical user interface to make the technology more accessible to artists."
info: "Senior Thesis at Middlebury College"
link: "https://cs.middlebury.edu"
role: ""
index: 6
---
import {FlexContainer, HalfWidth, ThirdWidth, TwoThirdsWidth } from '../../../components/post'

#### Introduction

<FlexContainer>
<ThirdWidth>
Given a large set of input-output pairs, a neural network can be trained to mimic the function f(x) that produced those pairs.
In 2019, X published a paper, showing how a neural network could be trained to mimic a mathematical function to produce artworks
that appear as if they came from the training dataset. While today AI image generation is widely known, in 2019 it was mostly limited to researchers.
</ThirdWidth>
<HalfWidth>
    ![neural network diagram](./nnet_diagram_export.jpg "Diagram of a neural network made of images generated by a neural network.")
</HalfWidth>
</FlexContainer>


#### Research Questions

<HalfWidth>
    Influenced by my coursework in both Computer Science and the liberal arts, my research questions straddled Machine Learning, Human-Computer Interaction, and Philosophy. The research questions were:

</HalfWidth>

<FlexContainer>
<ThirdWidth>

##### How can artistâ€™s leverage Generative Adversarial Networks for their own art-making?

</ThirdWidth>
<ThirdWidth>
    ##### Should we think of GANs as autonomous art-generating agents or as tools for artists?
</ThirdWidth>
</FlexContainer>

#### Datasets
<FlexContainer>
    <HalfWidth>
        The simplest way to influence the output images is by curating the images in the dataset used to train the model.

        I conducted my experiments on two different datasets: Impressionist and Abstract Expressionist.  I created these datasets by downloading real artworks with specific style tags from WikiArt, a free online visual encyclopedia.
    </HalfWidth>
    <ThirdWidth>

    </ThirdWidth>
</FlexContainer>

##### Impressionist
<FlexContainer>
    <ThirdWidth>
        3,684 works of 19th century Impressionist painting, including:

    </ThirdWidth>
    <ThirdWidth>
        ![Garden in Grez](./imp-sample/garden-in-grez.jpg "Garden in Grez, 1883, Carl Larsson")
    </ThirdWidth>
</FlexContainer>

<FlexContainer>
    <ThirdWidth>
        ![La Gare Saint-Lazare](./imp-sample/gare-st-lazare.jpg "La Gare Saint-Lazare, 1877, Claude Monet")
    </ThirdWidth>
    <ThirdWidth>
        ![The Railway](./imp-sample/railway.jpg "The Railway, 1873, Edouard Manet")
    </ThirdWidth>
    <ThirdWidth>
        ![The Grands Boulevards](./imp-sample/the-great-boulevards-1875.jpg "The Grands Boulevards, 1875, Pierre-Auguste Renoir")
    </ThirdWidth>
</FlexContainer>

##### Abstract Expressionist
<FlexContainer>
    <ThirdWidth>
        3,284 works of 20th century American abstract painting, including:

    </ThirdWidth>
    <ThirdWidth>
        ![Number 5](./abex-sample/No._5,_1948.jpg "Number 5, 1948, Jackson Pollock")
    </ThirdWidth>
</FlexContainer>

<FlexContainer>
    <ThirdWidth>
        ![Blue, Orange, Red](./abex-sample/blue-orange-red.jpg!Large.jpg "Blue, Orange, Red, 1961, Mark Rothko")
    </ThirdWidth>
    <ThirdWidth>
        ![Autumn Sky](./abex-sample/abstract-expressionist-autumn-sky-1953.jpg "Autumn Sky, 1953, Audrey Flack")
    </ThirdWidth>
</FlexContainer>


#### Experiments



##### Output Canvas Size
<FlexContainer>
<ThirdWidth>
    Output canvas size is a parameter of the network architecture.
    It determines how large of an image the neural network will output.

    I observed that the image would become increasingly complex and phenomena within the image would become disjoint and seemingly haphazard as image size was increased.
</ThirdWidth>
<HalfWidth>
    ![output size diagram](./output-size.jpg)
</HalfWidth>
</FlexContainer>

##### Training Time
<FlexContainer>
    <ThirdWidth>
        Training time is a parameter of network training and refers to how long we train the network before generating images.
        A training epoch is one pass through all the images in the training dataset.
        In my experiments, I generated images after 300, 600, 900, and 12,000 epochs.
    </ThirdWidth>
    <HalfWidth>
    </HalfWidth>
</FlexContainer>
<HalfWidth>
    ![training time diagram](./training-time.jpg)

</HalfWidth>




#### UI Prototype
dfsaf