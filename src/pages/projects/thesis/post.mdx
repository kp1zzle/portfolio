---
title: "Neural Networks for Artists"
date: "Spring 2019"
slug: "neural-networks-for-artists"
hero_image: "./hero.jpg"
hero_image_alt: "neural net diagram"
short_description: "How can artists use neural networks as creative tools?"
long_description: "How can artists use neural networks as creative tools? I analyzed the uses of this technology and how artists could change configuration and hyper-parameters to achieve desired results. Finally, I suggested a graphical user interface to make the technology more accessible to artists."
info: "Senior Thesis at Middlebury College"
link: "https://cs.middlebury.edu"
role: ""
index: 6
---
import {FlexContainer, HalfWidth, ThirdWidth } from '../../../components/post'

#### Introduction

<FlexContainer>
<ThirdWidth>
Given a large set of input-output pairs, a neural network can be trained to mimic the function f(x) that produced those pairs.
In 2019, X published a paper, showing how a neural network could be trained to mimic a mathematical function to produce artworks
that appear as if they came from the training dataset. While today AI image generation is widely known, in 2019 it was mostly limited to researchers.
</ThirdWidth>
<HalfWidth>
    ![neural network diagram](./nnet_diagram_export.jpg "Diagram of a neural network made of images generated by a neural network.")
</HalfWidth>
</FlexContainer>


#### Research Questions

<HalfWidth>
    Influenced by my coursework in both Computer Science and the liberal arts, my research questions straddled Machine Learning, Human-Computer Interaction, and Philosophy. The research questions were:

</HalfWidth>

<FlexContainer>
<ThirdWidth>

##### How can artistâ€™s leverage Generative Adversarial Networks for their own art-making?

</ThirdWidth>
<ThirdWidth>
    ##### Should we think of GANs as autonomous art-generating agents or as tools for artists?
</ThirdWidth>
</FlexContainer>

#### Datasets
<FlexContainer>
    <ThirdWidth>
        The simplest way to influence the output images is by curating the images in the dataset used to train the model.

        I conducted my experiments on two different datasets: Impressionist and Abstract Impressionist.  I created these datasets by downloading real artworks with specific style tags from WikiArt, a free online visual encyclopedia.
    </ThirdWidth>
    <HalfWidth>
        ![output size diagram](./output-size.jpg)
    </HalfWidth>
</FlexContainer>

##### Impressionist
<FlexContainer>
    <ThirdWidth>
        3,684 works of 19th century European painting, including:

    </ThirdWidth>
    <ThirdWidth>
        ![output size diagram](./output-size.jpg)
    </ThirdWidth>
</FlexContainer>

<FlexContainer>
    <ThirdWidth>
        ![output size diagram](./output-size.jpg)
    </ThirdWidth>
    <ThirdWidth>
        ![output size diagram](./output-size.jpg)
    </ThirdWidth>
    <ThirdWidth>
        ![output size diagram](./output-size.jpg)
    </ThirdWidth>
</FlexContainer>


#### Experiments



##### Output Canvas Size
<FlexContainer>
<ThirdWidth>
    Output canvas size is a parameter of the network architecture.
    It determines how large of an image the neural network will output.

    I observed that the image would become increasingly complex and phenomena within the image would become disjoint and seemingly haphazard as image size was increased.
</ThirdWidth>
<HalfWidth>
    ![output size diagram](./output-size.jpg)
</HalfWidth>
</FlexContainer>

##### Training Time


#### UI Prototype
dfsaf